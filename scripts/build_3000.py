import json
import os
import math
from pypinyin import pinyin, Style

# --- 配置区 ---
OUTPUT_INDEX_FILE = "../src/data/chars_index.json"
OUTPUT_DETAIL_DIR = "../public/data"

# 确保输出目录存在
if not os.path.exists(OUTPUT_DETAIL_DIR):
    os.makedirs(OUTPUT_DETAIL_DIR)

# 常用汉字 Top 500 (作为演示，实际请自行替换为 3000 字字符串)
RAW_CHARS = """
饲灭严晚盐政晋双俊哺慎骂厨蛛燥诊飞新隔墩齐记颈碧病吸尘谁疗煎信闷土格挠犬腊淘从弄弟懂汁俯疾董皂圆伍宪蛇偏校较号忆哼嗓便到风肝敝役哄疯户窗指梨验月仇魄娘治诉获胆祷袋键称撤定洪叮拦邀筐四纹览控焙谢通狡简园窃凹作捕互庭府销瘩浆给喜联洗灰憋认成很询六秒贱狮羊哥复冤福表周剧繁资江乔赶青顾八牌谦石财仓着除宁怕升批每参仅梅雅博丙踩烤篇海血横恼浊炊值谈妙段毁罪弦叙扫勺朋熔要靶奖进辈解郊积竹眨坝杜欲允蕉区婆我厅佛妈怒鸟骗荷由登绢同溉驱覆悲灵洁筛氮面锻穷刮识似渴筝险母扁在放木寨窝挡始势企技绒跃爷如喝描寄脉古脆罩感不珠许雾猴板涝嘉捉殃男漫衬粉陪应屠辫约拜首脂倘忙群抄都瓦胳民绳找欠塑茧境它磨贵锄拘知冲图幻削说笋烘趟巡裤片恨庸金戏也撒透职志馋楚挨之中姓歪伶版依装军荣状宇炭总春陷鬼布轻律九社寺教婚箱增象册搞关曾茂替漠轨件侄顺剂浪假轰剩旅肢芹驻鲜孩厚洋殆那彬些秃肾款付终夹或劫激忌慌债砍誓讯华护损康暖戴披搁癌肌却催士吴馆白快涛盼常闹乐签舞陵棵楼惑雄丽械贫朗杀添系谱榆担本胃恐犯相旨叼乱载稳歼垫储桌隆演测悄衔功虫省贝枕尝但移第括三纠摇绿慨迪东限尸连坐奸何俭钓按监故俩孔理析锯迷刑们目龟爹瞠岁亩蝇爪把充瞒施级舶晓察盛药女垮休肯细只椅插衫略铅僻浙跟肉霸然贺艘竟姑卸数亦十苦佃虚缴柳蛙孝咐徒炎眠熄席铁蓬糊各冻速措前释喊什最带唤钳脯者领骨胖学吨痕哨实承遮矮羽运宿旋己桥量螺烧稀汉就一岛橡达置产亲鳌导韵壮辜丸羡毫扒家强歉杨叠垒撮鸦早砖顽柏张唇配烫围雹过蓄扭刁猾垃亭葱璧叫协必焰静纲司现划厕琴虑迅标揉违贡旬物妹宾倾磋膜骡此屋死详息岗箔渠劣索鸣嗽暮期贬阔刻重辛厂她巢场胶庄拼副谋亏西锁外筋絮玩滔微呆调啄叶滴惠抗伯灿乙他底交富且脏洞悔耻暗旗近核洲桨货尽菌翟廊门豹匪怜威菜勿障服机盗拢堂帐闲摩安腔掩艇津瀑践艰后观驶真握闭宵痘照纯猜涌累持试笑留帝袄动态鳖盟膛刘迭迈剃霞嫁逼浮乳声绩悉手还赏屯众滨饼奥箩忠狭屡鼻断蜓呜鸽边百朽奇惧灯蜜纺锣熬虎免震豆砌去锭葛引姿帽拾射对端伤厘命狼干候铺盆看伟肚聚球沟夏禁食狠骆镜滋质厦宰绸句辰忍人视朵匆补匀入聋袭敬萝鱼离没商扰老傲歹浸斯费辽特搂计可睹截满爽扯笨路么惭酬推编衰胡源缩巩君歇芒钢吼辟竿侦台冰纳祸文碍矗召行尚沫捎卧碟掠辩芳个采碗往稍曲鼎沸肃是骑谎米加寸挑久峡德耐刃程块杂扩昂非锡煤顷堆绣捧牧随皮脱画矿搜芦淀尼杠昏欺备恋培搐骋泪仙蛮任果凭穗和两盯闻贷诱纷净尿斑笼银口初泉请论捏饮掘尺躺科情短孤裹染京遇字饶乌捡赌阵勤秋睬昨够哀焦竞岸棉聪茄将团符准几右燃族埋喇腹崇牛温蒙骇归壁蚊热子贿该甲返膝换黎夕赖滚桃梯散捆晌挂殊碘哈央拴傣已怨年印五盖卖得岭翱伐胞衣抱邻逗电忘誉煌迫刊盏塞顶力瓜午刺献谣绘背抽阿悼仰鞋窑删退念官阻私落智窿樱岩济哪悟偶节畴撇语敦桶龄垂抚思美烦徐铸申趋点趴贴臭灶缠固次直脚猛切压健陡槐这儿沈医泥轮打书谅待提拐钩帜斌姐敲典料稼上其延绝呼吗保牢锹率属党脑童巷娱变序网襟于褂滩疤蹦彻恩梦茎驰莫怀赞发凡晨兴搭具谨逛痰拨稠巴诗托妥致位惮竭菊崭惨烈丑疫小吉扬雨址港珐员主枝斜惊裳豪浴漏蛾映堪傻璃虾妄迎消即炒缎肿碰冬育谤泼赴般宅乏另公码掀猪界肥乒示咽溪档原蜘池判傅需逢秧帅痒勇掉种摆圾占反醋框叛墓挫羞宽轿虹丝吐艺务蒸赛录吊遁伞辅漂套偷麦斧勾遥寇俗柴才碌诞涨拣矛法夜盈吧飘晴菠朱榨供川蔽居胜汽欣蚂航岔响兑友清梳排踢歌捐玻犹矩崩湾库押甚售祖祥循妇澳购狸多雀滤骄性婶跳丢方经饭狱宏绵易附自趣隶班讲设愉起须摊零大邓事洽防举缸辱侮择椒专捷屑藏乖凳冒扑懒当泛丛题桐揭扔沙向姥熟忧架某代膏惩皱亿鞭嫂明翅鹿棚拿佳悠乓拔桂粮滥拥暴疲撕狐舌姨林吓份弹列著伸化低活筹述途臣修觉涤胸裂父辆并荒巾惦时缓忽锦吩尾昆罚集练鹊梁茶爱逝传衡牺借甩亚迁躲软回妖摘冷算街绍拖唐卡世娃遭昌伪研言跋帘夫例正剪哭夸殿呈怪花眉貌姜幅剑券穴院敌取躬猫阴误玉稿甸下让了奉贸趁渗光刷舰柿斤凤构证征瓶摔困萍被探匹影坡浇吞帮铜章车孟屈雁渔错予喉你共效侈适紫晒粗蹬葡逃雕湖惹捣柄驼臂屿访勒维径听夺坛宝钟络隐卫逆确蚕贞紧饰糖余颜今范倡仁堵锅狂规缺坚毯秀澈庙愁侨恢泻腰颗揣箭望葬喂萄疏贯仔泡冈禾粥蚁汇译层神秩拉跨腿遗粘踪蜡匙翼奔栽星像鲁筒弱以策剖心里半链帆勉束惯阅叹惰丹做患条俱撑晶根椽虏壶哑油令掂野棍鸭苞宠蹈乞术抬绑执乎跺混篮身审废害香杯哗树钱仪千兔喷续粪贼步类渡睡粱炸昼兼耍凑长蹲残脊逮堤脾敢沃继讨训扇盘播决急柜钻刚材庆样草拒慧降的欢纵宋想萌派至好密笛苍炮鹅问锈澡唱差痛栗侍伴欧弯奶超与走市饱馅隘鼓蝶立买辨劲掰介店李度弃戒汤跑缘道扶股怠塔蜻用平僵使巧阀芽畏仆蒜案沾串临霜岂础竖难甜地选收陈山咬兽塘腥顿怎莲式寒嫩傍毛渐庵胁粒挺陶眯词郑争城革救柔卵柱浑恭角赤广历展存掸会蝴桑裁酒腐甘倚恶烛出晕丧荡注鹰接纱局泽殖踏虽暂刀侧颂慈戳毅饺站拌少品助丁希挣越邪劝闸彩委挤卜摧波偿头秤抢哲缝嘱丘极遣坑迟处晃裕御纸坏危形锤黄别空抓体隙扣页熊含寻耗减丈弊兆浅污倍湿睁报姻封懊尖生您冠叔输天拳厉考客诚乘所显轧跌话七爸纤饿墙踌漆谷折茫帖铃嫌奋弓液脸吵蔬舟敞检告遍犁奠戚战抵止厌价否咳翻鄙扛匠恳钉享无查既精碑赚名驴苗兄峰掣蛋捞敏葵蚀棕杏答比狄酸蒂督膀愤膘红瞎造旷内善据彼订未挪业因畅骤腾汪距又包型肤亮垄杰愚稻失袖纽榜邮裙窄努宫泊谜等悦云史郴耕停阳游援房评埠益膊涉投来高廉渣亡再枪症圣改撞槽棒击溜基氏幕沿洒挎泳怖赔恒南支闯幸管鸡秘奴孙概唉环容辉僚克宜武雪北而割及瞧肺全议闪兰盒钥制赢痴咱妻授肠饥呀滑醉田币励喘负英窜侵烂师麻淡贪翠宴咏远永课郎毕水栏州色悬估凶崖组仗硬鉴递受攻舒宣搬养愧国毙农旦末龙义壳利河仿县阁守枯艳辣森先舅浩舱租锐旧拍奏碎景爬牙嫡票剥部深若旺胀祝转蓝酿为讽预谊鼠优卷突扮搅棋禽苹绪盾妒见泄旱镀寿诵礼眼酷振朴翁淋氧坟浓皆陆项绞舍更间揪阶耳季挖牲芬袍瘦凋滇宗恰室秆逐掏则旁暑斗求芝抛珍败膨万均能泰呢瘪绕域际二住火袜冶笔肩扎破尊太单齿完拆枣涂栋啦沉招写携坦船佩异追驾村霉愈靠酱唯狗床糙宙挥畜统建牵赵送究线触愿巨元慕惜营素独疮瞪妨松音株抖普煮掌锋纪流孕磁合墨垛黑权俘倒镇伏劳耽疑日味圈斥汗凯队有罢挽伙杆启垦馒毒植坊斩惕织吃乃猎责榴凉气创啊慢苏凝朝罗烟堡糠谍倦炕足驳糕佣兵荐座咸税促淹疼蜂睛诸茅迹钞蔑糟针皇意铲雷润梢左办镰抹叨娇贤幼读跪炼况灾模贩脖结良仍分吹穿届辞番盲筑炉陕避兜

"""

# 清洗去重
CHARS_LIST = list(dict.fromkeys([c for c in RAW_CHARS if c.strip()]))

def get_pinyin_tone(char):
    # 获取带声调拼音: zhōng
    return pinyin(char, style=Style.TONE, heteronym=False)[0][0]

def main():
    print(f"Processing {len(CHARS_LIST)} characters...")
    
    full_data = []
    
    for i, char in enumerate(CHARS_LIST):
        # 构造完整数据对象
        char_data = {
            "id": f"h_{i+1}",
            "char": char,
            "pinyin": get_pinyin_tone(char),
            "level": (i // 100) + 1, # 每100字一级
            "stroke": 5, # 暂时mock，Day 2引入真实数据
            "example": f"{char}词", 
            "confusingIds": [] # Day 2 填充
        }
        full_data.append(char_data)

    # 1. 生成轻量索引 (src/data/chars_index.json)
    # 仅包含最基础信息，用于列表展示和搜索，减小主包体积
    index_data = [{
        "id": c["id"], 
        "char": c["char"], 
        "level": c["level"]
    } for c in full_data]
    
    with open(OUTPUT_INDEX_FILE, 'w', encoding='utf-8') as f:
        json.dump(index_data, f, ensure_ascii=False)
    print(f"Generated Index: {len(index_data)} items -> {OUTPUT_INDEX_FILE}")

    # 2. 生成分片详情 (public/data/chars_detail_X.json)
    # 按需加载详情（拼音、组词、干扰项）
    CHUNK_SIZE = 200
    total_chunks = math.ceil(len(full_data) / CHUNK_SIZE)
    
    for i in range(total_chunks):
        start = i * CHUNK_SIZE
        end = start + CHUNK_SIZE
        chunk = full_data[start:end]
        
        # 转为 Map 结构方便查找: { "h_1": {...} }
        chunk_map = {c["id"]: c for c in chunk}
        
        filename = f"chars_detail_{i}.json"
        filepath = os.path.join(OUTPUT_DETAIL_DIR, filename)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(chunk_map, f, ensure_ascii=False)
            
    print(f"Generated Details: {total_chunks} chunks -> {OUTPUT_DETAIL_DIR}")

if __name__ == "__main__":
    main()